# LangGraph Workflow Flowchart - Travel AI Assistant

## ğŸ“Š Overall Architecture

```mermaid
graph TD
    A[ğŸš€ User Input] --> B{ğŸ“ Input Type?}
    B -->|Text Only| C[ğŸ“„ Text Query]
    B -->|Image + Text| D[ğŸ–¼ï¸ Image Data]
    B -->|Image Only| D
    
    C --> E[ğŸ” analyze_input Node]
    D --> E
    
    E --> F[ğŸ“š retrieve_docs Node]
    F --> G[ğŸ¤– generate_response Node]
    G --> H[âœ… Final Response]
    
    subgraph "ğŸ—ï¸ LangGraph Workflow"
        E
        F  
        G
    end
    
    subgraph "ğŸ“¦ AgentState"
        I[messages: List[str]]
        J[query: str]
        K[query_type: str]
        L[image_data: str]
        M[retrieved_docs: List[str]]
        N[response: str]
    end
```

## ğŸ”„ Detailed Node Processing

```mermaid
graph TD
    subgraph "ğŸ” Node 1: analyze_input"
        A1[Input State] --> B1{Has Image?}
        B1 -->|Yes| C1[ğŸ–¼ï¸ Call Vision API]
        B1 -->|No| D1[ğŸ“„ Keep Text Query]
        
        C1 --> E1{Vision Success?}
        E1 -->|Yes| F1[âœ… Update query with image analysis]
        E1 -->|No| G1[âŒ Fallback to text processing]
        
        D1 --> H1[Set query_type = 'text']
        F1 --> I1[Set query_type = 'image'] 
        G1 --> H1
        
        H1 --> J1[Output State]
        I1 --> J1
    end
    
    subgraph "ğŸ“š Node 2: retrieve_docs"
        A2[Input State] --> B2[ğŸ” ChromaDB Search]
        B2 --> C2[ğŸ“Š Vector Similarity]
        C2 --> D2[ğŸ” Top 3 Results]
        D2 --> E2{Results Found?}
        E2 -->|Yes| F2[âœ… Update retrieved_docs]
        E2 -->|No| G2[âŒ Empty retrieved_docs]
        F2 --> H2[Output State]
        G2 --> H2
    end
    
    subgraph "ğŸ¤– Node 3: generate_response"
        A3[Input State] --> B3[ğŸ“‹ Build Context]
        B3 --> C3[ğŸ”§ Create System Prompt]
        C3 --> D3[ğŸš€ Call GPT-5]
        D3 --> E3{LLM Success?}
        E3 -->|Yes| F3[âœ… Process Response]
        E3 -->|No| G3[âŒ Error Response]
        
        F3 --> H3[ğŸ—ºï¸ Add Google Maps Links]
        H3 --> I3[âœ… Update response]
        G3 --> I3
        I3 --> J3[Output State]
    end
```

## ğŸ¯ State Flow Through Nodes

```mermaid
graph LR
    subgraph "Initial State"
        A[messages: []]
        B[query: 'User input']
        C[query_type: 'text'] 
        D[image_data: base64 | null]
        E[retrieved_docs: []]
        F[response: '']
    end
    
    subgraph "After analyze_input"
        A1[messages: []]
        B1[query: 'Processed query']
        C1[query_type: 'text' | 'image']
        D1[image_data: base64 | null]
        E1[retrieved_docs: []]
        F1[response: '']
    end
    
    subgraph "After retrieve_docs"
        A2[messages: []]
        B2[query: 'Processed query']
        C2[query_type: 'text' | 'image']
        D2[image_data: base64 | null]
        E2[retrieved_docs: ['doc1', 'doc2', 'doc3']]
        F2[response: '']
    end
    
    subgraph "After generate_response"
        A3[messages: []]
        B3[query: 'Processed query']
        C3[query_type: 'text' | 'image']
        D3[image_data: base64 | null]
        E3[retrieved_docs: ['doc1', 'doc2', 'doc3']]
        F3[response: 'Final AI response']
    end
    
    A --> A1
    B --> B1
    C --> C1
    D --> D1
    E --> E1
    F --> F1
    
    A1 --> A2
    B1 --> B2
    C1 --> C2
    D1 --> D2
    E1 --> E2
    F1 --> F2
    
    A2 --> A3
    B2 --> B3
    C2 --> C3
    D2 --> D3
    E2 --> E3
    F2 --> F3
```

## ğŸ”€ Decision Flow

```mermaid
graph TD
    START[ğŸš€ process_query called] --> INIT[ğŸ“¦ Initialize AgentState]
    
    INIT --> NODE1[ğŸ” analyze_input]
    
    NODE1 --> DECISION1{ğŸ–¼ï¸ Has Image?}
    DECISION1 -->|Yes| VISION[ğŸ‘ï¸ Call Vision API]
    DECISION1 -->|No| TEXT[ğŸ“ Process as Text]
    
    VISION --> VISION_OK{âœ… Vision Success?}
    VISION_OK -->|Yes| UPDATE_QUERY[ğŸ“ Update query with vision result]
    VISION_OK -->|No| FALLBACK[âš ï¸ Fallback to text mode]
    
    UPDATE_QUERY --> NODE2[ğŸ“š retrieve_docs]
    TEXT --> NODE2
    FALLBACK --> NODE2
    
    NODE2 --> SEARCH[ğŸ” ChromaDB Vector Search]
    SEARCH --> SEARCH_OK{ğŸ“Š Found Results?}
    SEARCH_OK -->|Yes| GET_DOCS[ğŸ“‹ Get Top 3 Documents]
    SEARCH_OK -->|No| NO_DOCS[âŒ No relevant docs]
    
    GET_DOCS --> NODE3[ğŸ¤– generate_response]
    NO_DOCS --> NODE3
    
    NODE3 --> BUILD_CONTEXT[ğŸ”§ Build Context from Docs]
    BUILD_CONTEXT --> PROMPT[ğŸ“‹ Create System Prompt]
    PROMPT --> LLM[ğŸš€ Call Azure OpenAI GPT-5]
    
    LLM --> LLM_OK{âœ… LLM Success?}
    LLM_OK -->|Yes| PROCESS[âš™ï¸ Process Response]
    LLM_OK -->|No| ERROR[âŒ Generate Error Message]
    
    PROCESS --> MAPS[ğŸ—ºï¸ Add Google Maps Links]
    MAPS --> END[âœ… Return Final Response]
    ERROR --> END
```

## ğŸ® Example Execution Flow

```mermaid
graph TD
    subgraph "Example: User uploads image of Pho + asks 'What is this?'"
        EX1[User Input: Image + 'ÄÃ¢y lÃ  mÃ³n gÃ¬?']
        EX1 --> EX2[analyze_input: Vision API identifies 'Phá»Ÿ bÃ²']
        EX2 --> EX3[retrieve_docs: Search ChromaDB for 'Phá»Ÿ bÃ²']
        EX3 --> EX4[ChromaDB returns: 3 documents about Pho]
        EX4 --> EX5[generate_response: GPT-5 + Context]
        EX5 --> EX6[Final: 'ÄÃ¢y lÃ  phá»Ÿ bÃ², mÃ³n Äƒn truyá»n thá»‘ng...']
        
        style EX1 fill:#e1f5fe
        style EX2 fill:#f3e5f5
        style EX3 fill:#e8f5e8
        style EX4 fill:#fff3e0
        style EX5 fill:#fce4ec
        style EX6 fill:#f1f8e9
    end
```

## ğŸ› ï¸ Error Handling Flow

```mermaid
graph TD
    A[Node Execution] --> B{Error Occurs?}
    B -->|No| C[âœ… Continue to Next Node]
    B -->|Yes| D{Which Node?}
    
    D -->|analyze_input| E[ğŸ–¼ï¸ Vision API Error]
    D -->|retrieve_docs| F[ğŸ“š ChromaDB Error]  
    D -->|generate_response| G[ğŸ¤– LLM API Error]
    
    E --> E1[Set fallback query]
    E1 --> H[Continue Pipeline]
    
    F --> F1[Set empty retrieved_docs]
    F1 --> H
    
    G --> G1[Set error response]
    G1 --> I[Return Error to User]
    
    H --> C
    C --> J[Next Node | END]
```

## ğŸ“ˆ Performance & Monitoring

```mermaid
graph TD
    subgraph "Monitoring Points"
        M1[ğŸ” analyze_input timing]
        M2[ğŸ“š ChromaDB query time] 
        M3[ğŸ¤– GPT-5 response time]
        M4[ğŸ—ºï¸ Post-processing time]
    end
    
    subgraph "Debug Logs"
        L1[Image data length]
        L2[Vision API response]
        L3[Retrieved documents count]
        L4[Final response length]
    end
    
    subgraph "Error Tracking"
        E1[Vision API failures]
        E2[ChromaDB connection errors]
        E3[GPT-5 API errors]
        E4[Timeout errors]
    end
```

## ğŸ¯ Key Benefits Visualization

```mermaid
graph TD
    subgraph "ğŸ—ï¸ LangGraph Benefits"
        B1[ğŸ“Š Stateful Processing]
        B2[ğŸ”§ Modular Design]
        B3[ğŸ›¡ï¸ Error Isolation]
        B4[ğŸ“ˆ Easy Extension]
        B5[ğŸ” Debuggable]
        B6[âš¡ Parallelizable]
    end
    
    B1 --> D1[State flows through all nodes automatically]
    B2 --> D2[Each node has single responsibility]
    B3 --> D3[Node failure doesn't crash pipeline]
    B4 --> D4[Add new nodes without breaking existing flow]
    B5 --> D5[Trace state changes at each step]
    B6 --> D6[Can run independent nodes in parallel]
```
